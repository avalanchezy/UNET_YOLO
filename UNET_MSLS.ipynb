{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 3133/3133 [00:30<00:00, 102.53it/s]\n",
      "Loading dataset: 100%|██████████| 783/783 [00:07<00:00, 103.24it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import monai\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    EnsureChannelFirstd,\n",
    "    ScaleIntensityd,\n",
    "    ToTensord,\n",
    ")\n",
    "from monai.data import CacheDataset, DataLoader\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.optimizers import Novograd\n",
    "from monai.inferers import sliding_window_inference\n",
    "import torch\n",
    "\n",
    "# Set up the directory paths for images and labels\n",
    "base_dir = \"./datasets/data/datasets_unet/\"\n",
    "image_dir_train = os.path.join(base_dir, \"train/images\")\n",
    "label_dir_train = os.path.join(base_dir, \"train/masks\")\n",
    "image_dir_val = os.path.join(base_dir, \"val/images\")\n",
    "label_dir_val = os.path.join(base_dir, \"val/masks\")\n",
    "# image_dir_test = os.path.join(base_dir, \"test/images\")\n",
    "# label_dir_test = os.path.join(base_dir, \"test/masks\")\n",
    "\n",
    "# Get the list of image and label files\n",
    "images_train = sorted([os.path.join(image_dir_train, f) for f in os.listdir(image_dir_train) if f.endswith('.png')])\n",
    "labels_train = sorted([os.path.join(label_dir_train, f) for f in os.listdir(label_dir_train) if f.endswith('.png')])\n",
    "images_val = sorted([os.path.join(image_dir_val, f) for f in os.listdir(image_dir_val) if f.endswith('.png')])\n",
    "labels_val = sorted([os.path.join(label_dir_val, f) for f in os.listdir(label_dir_val) if f.endswith('.png')])\n",
    "# images_test = sorted([os.path.join(image_dir_test, f) for f in os.listdir(image_dir_test) if f.endswith('.png')])\n",
    "# labels_test = sorted([os.path.join(label_dir_test, f) for f in os.listdir(label_dir_test) if f.endswith('.png')])\n",
    "\n",
    "# Create a list of dictionaries for paired image and label paths\n",
    "data_dicts_train = [{'image': image_name, 'label': label_name} for image_name, label_name in zip(images_train, labels_train)]\n",
    "data_dicts_val = [{'image': image_name, 'label': label_name} for image_name, label_name in zip(images_val, labels_val)]\n",
    "# data_dicts_test = [{'image': image_name, 'label': label_name} for image_name, label_name in zip(images_test, labels_test)]\n",
    "\n",
    "# Define the transformations to preprocess the images\n",
    "train_transforms = Compose([\n",
    "    LoadImaged(keys=['image', 'label']),\n",
    "    EnsureChannelFirstd(keys=['image', 'label']),\n",
    "    ScaleIntensityd(keys=['image', 'label']),\n",
    "    ToTensord(keys=['image', 'label']),\n",
    "])\n",
    "val_transforms = Compose([\n",
    "    LoadImaged(keys=['image', 'label']),\n",
    "    EnsureChannelFirstd(keys=['image', 'label']),\n",
    "    ScaleIntensityd(keys=['image', 'label']),\n",
    "    ToTensord(keys=['image', 'label']),\n",
    "])\n",
    "# test_transforms = Compose([\n",
    "#     LoadImaged(keys=['image', 'label']),\n",
    "#     EnsureChannelFirstd(keys=['image', 'label']),\n",
    "#     ScaleIntensityd(keys=['image', 'label']),\n",
    "#     ToTensord(keys=['image', 'label']),\n",
    "# ])\n",
    "\n",
    "# Create a MONAI dataset and a data loader for training\n",
    "train_ds = CacheDataset(data=data_dicts_train, transform=train_transforms, cache_rate=1.0)\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True)\n",
    "val_ds = CacheDataset(data=data_dicts_val, transform=val_transforms, cache_rate=1.0)\n",
    "val_loader = DataLoader(val_ds, batch_size=2, shuffle=True)\n",
    "# test_ds = CacheDataset(data=data_dicts_test, transform=test_transforms, cache_rate=1.0)\n",
    "# test_loader = DataLoader(test_ds, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torch._dynamo' has no attribute 'external_utils' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Engine, Events\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping, ModelCheckpoint\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmonai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnetworks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UNet\n",
      "File \u001b[1;32mc:\\Users\\zhuyi\\Desktop\\INSA\\env\\lib\\site-packages\\ignite\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhuyi\\Desktop\\INSA\\env\\lib\\site-packages\\ignite\\engine\\__init__.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Engine\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CallableEventWithFilter, EventEnum, Events, EventsList, RemovableEventHandle, State\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Metric\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_tensor\n\u001b[0;32m     13\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mState\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_supervised_trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupervised_evaluation_step_amp\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     30\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\zhuyi\\Desktop\\INSA\\env\\lib\\site-packages\\ignite\\metrics\\__init__.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mepoch_metric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EpochMetric\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfbeta\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Fbeta\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfrequency\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Frequency\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgan\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FID\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgan\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minception_score\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InceptionScore\n",
      "File \u001b[1;32mc:\\Users\\zhuyi\\Desktop\\INSA\\env\\lib\\site-packages\\ignite\\metrics\\frequency.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01midist\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Engine, Events\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtiming\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Timer\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Metric, reinit__is_reduced, sync_all_reduce\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFrequency\u001b[39;00m(Metric):\n",
      "File \u001b[1;32mc:\\Users\\zhuyi\\Desktop\\INSA\\env\\lib\\site-packages\\ignite\\handlers\\__init__.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Engine\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Events\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Checkpoint, DiskSaver, ModelCheckpoint\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mearly_stopping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mema_handler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EMAHandler\n",
      "File \u001b[1;32mc:\\Users\\zhuyi\\Desktop\\INSA\\env\\lib\\site-packages\\ignite\\handlers\\checkpoint.py:17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Version(torch\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.9.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ZeroRedundancyOptimizer\n\u001b[0;32m     19\u001b[0m     HAVE_ZERO \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\zhuyi\\Desktop\\INSA\\env\\lib\\site-packages\\torch\\distributed\\optim\\__init__.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional_rprop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _FunctionalRprop\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional_sgd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _FunctionalSGD\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnamed_optimizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _NamedOptimizer\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m as_functional_optim\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# DistributedOptimizer imports torch.distributed.rpc names, so gate availability\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# based on RPC being available.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhuyi\\Desktop\\INSA\\env\\lib\\site-packages\\torch\\distributed\\optim\\named_optimizer.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optim\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_shard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msharded_tensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ShardedTensor\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfsdp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FullyShardedDataParallel \u001b[38;5;28;01mas\u001b[39;00m FSDP\n\u001b[0;32m     14\u001b[0m __all__: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     16\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zhuyi\\Desktop\\INSA\\env\\lib\\site-packages\\torch\\distributed\\fsdp\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_flat_param\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FlatParameter \u001b[38;5;28;01mas\u001b[39;00m FlatParameter\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfully_sharded_data_parallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     BackwardPrefetch,\n\u001b[0;32m      4\u001b[0m     CPUOffload,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     StateDictType,\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     21\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBackwardPrefetch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCPUOffload\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStateDictType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\zhuyi\\Desktop\\INSA\\env\\lib\\site-packages\\torch\\distributed\\fsdp\\_flat_param.py:30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfsdp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_common_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     31\u001b[0m     _FSDPDeviceHandle,\n\u001b[0;32m     32\u001b[0m     _named_parameters_with_duplicates,\n\u001b[0;32m     33\u001b[0m     _no_dispatch_record_stream,\n\u001b[0;32m     34\u001b[0m     _same_storage_as_data_ptr,\n\u001b[0;32m     35\u001b[0m     _set_fsdp_flattened,\n\u001b[0;32m     36\u001b[0m     HandleTrainingState,\n\u001b[0;32m     37\u001b[0m )\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _alloc_storage, _free_storage, _p_assert\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparameter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ParameterMeta  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhuyi\\Desktop\\INSA\\env\\lib\\site-packages\\torch\\distributed\\fsdp\\_common_utils.py:30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_composable_state\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _get_module_state, _State\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdevice_mesh\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeviceMesh\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_checkpoint\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint_wrapper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     32\u001b[0m     _CHECKPOINT_PREFIX,\n\u001b[0;32m     33\u001b[0m )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfsdp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fsdp_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FSDPExtensions\n",
      "File \u001b[1;32mc:\\Users\\zhuyi\\Desktop\\INSA\\env\\lib\\site-packages\\torch\\distributed\\_tensor\\__init__.py:346\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _dtensor_init_helper(\n\u001b[0;32m    335\u001b[0m         torch\u001b[38;5;241m.\u001b[39mzeros,\n\u001b[0;32m    336\u001b[0m         torch_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    341\u001b[0m         placements\u001b[38;5;241m=\u001b[39mplacements,\n\u001b[0;32m    342\u001b[0m     )\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_running_with_deploy():\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo_utils\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhuyi\\Desktop\\INSA\\env\\lib\\site-packages\\torch\\distributed\\_tensor\\_dynamo_utils.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m allow_in_graph\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DTensor\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# dynamo/torch.compile utils for\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhuyi\\Desktop\\INSA\\env\\lib\\site-packages\\torch\\_dynamo\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m allowed_functions, convert_frame, eval_frame, resume_execution\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcode_context\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m code_context\n",
      "File \u001b[1;32mc:\\Users\\zhuyi\\Desktop\\INSA\\env\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py:62\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mguards\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     57\u001b[0m     CheckFunctionManager,\n\u001b[0;32m     58\u001b[0m     get_and_maybe_log_recompilation_reason,\n\u001b[0;32m     59\u001b[0m     GuardedCode,\n\u001b[0;32m     60\u001b[0m )\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Hooks\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OutputGraph\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreplay_record\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExecutionRecord\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_convert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InstructionTranslator, SpeculationLog\n",
      "File \u001b[1;32mc:\\Users\\zhuyi\\Desktop\\INSA\\env\\lib\\site-packages\\torch\\_dynamo\\output_graph.py:39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sympy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PythonReferenceAnalysis\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mweak\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WeakTensorKeyDictionary\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config, logging \u001b[38;5;28;01mas\u001b[39;00m torchdynamo_logging, variables\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CompiledFn, CompilerFn\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_transformation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     42\u001b[0m     create_call_function,\n\u001b[0;32m     43\u001b[0m     create_instruction,\n\u001b[0;32m     44\u001b[0m     Instruction,\n\u001b[0;32m     45\u001b[0m     unique_id,\n\u001b[0;32m     46\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\zhuyi\\Desktop\\INSA\\env\\lib\\site-packages\\torch\\_dynamo\\variables\\__init__.py:68\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn_module\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NNModuleVariable, UnspecializedNNModuleVariable\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     62\u001b[0m     FakeItemVariable,\n\u001b[0;32m     63\u001b[0m     NumpyNdarrayVariable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     UnspecializedPythonVariable,\n\u001b[0;32m     67\u001b[0m )\n\u001b[1;32m---> 68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     69\u001b[0m     TorchCtxManagerClassVariable,\n\u001b[0;32m     70\u001b[0m     TorchInGraphFunctionVariable,\n\u001b[0;32m     71\u001b[0m     TorchVariable,\n\u001b[0;32m     72\u001b[0m )\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01muser_defined\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UserDefinedClassVariable, UserDefinedObjectVariable\n\u001b[0;32m     75\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutogradFunctionContextVariable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutogradFunctionVariable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWithExitFunctionVariable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    129\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\zhuyi\\Desktop\\INSA\\env\\lib\\site-packages\\torch\\_dynamo\\variables\\torch.py:95\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m     80\u001b[0m     constant_fold_functions\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m     81\u001b[0m         [\n\u001b[0;32m     82\u001b[0m             torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mis_initialized,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     85\u001b[0m         ]\n\u001b[0;32m     86\u001b[0m     )\n\u001b[0;32m     89\u001b[0m tracing_state_functions \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     92\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39m_symbolic_trace\u001b[38;5;241m.\u001b[39mis_fx_tracing: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     94\u001b[0m     torch\u001b[38;5;241m.\u001b[39monnx\u001b[38;5;241m.\u001b[39mis_in_onnx_export: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m---> 95\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexternal_utils\u001b[49m\u001b[38;5;241m.\u001b[39mis_compiling: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     96\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39mis_compiling: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     97\u001b[0m }\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBaseTorchVariable\u001b[39;00m(VariableTracker):\n\u001b[0;32m    101\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"common base for all torch.* functions, classes, modules and other things\"\"\"\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'torch._dynamo' has no attribute 'external_utils' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.handlers import EarlyStopping, ModelCheckpoint\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, ScaleIntensityd, ToTensord\n",
    ")\n",
    "from monai.data import CacheDataset, DataLoader\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "\n",
    "\n",
    "# Set up the U-Net model\n",
    "model = UNet(\n",
    "    spatial_dims=2,  # Use `spatial_dims` instead of `dimensions` if needed\n",
    "    in_channels=1,\n",
    "    out_channels=1, # If your dataset has binary segmentation, you need only 1 output channel\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=Norm.BATCH,\n",
    ")\n",
    "# After initializing the model, move it to the GPU\n",
    "# model = model.cuda()\n",
    "\n",
    "\n",
    "# Set up the loss function and optimizer\n",
    "loss_function = DiceLoss(to_onehot_y=False, sigmoid=True)\n",
    "optimizer = Novograd(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "model_dir = './models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Assuming model, train_loader, val_loader, optimizer, and loss_function are already defined\n",
    "\n",
    "# Define the training step\n",
    "def train_step(engine, batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    inputs, labels = batch['image'], batch['label']\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_function(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "trainer = Engine(train_step)\n",
    "\n",
    "# Define the validation step\n",
    "def validation_step(engine, batch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs, labels = batch['image'], batch['label']\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "    return loss.item()\n",
    "\n",
    "evaluator = Engine(validation_step)\n",
    "\n",
    "# Define the score function for early stopping\n",
    "def score_function(engine):\n",
    "    return -engine.state.metrics['average_loss']\n",
    "\n",
    "# Attach the validation metric (loss) to the evaluator\n",
    "from ignite.metrics import RunningAverage\n",
    "RunningAverage(output_transform=lambda x: x).attach(evaluator, 'average_loss')\n",
    "\n",
    "# Setup model checkpoint to save the best model based on validation loss\n",
    "# checkpoint_handler = ModelCheckpoint(model_dir, 'checkpoint', n_saved=1, create_dir=True, score_function=score_function, score_name='val_loss', global_step_transform=global_step_from_engine(trainer))\n",
    "checkpoint_handler = ModelCheckpoint(model_dir, 'checkpoint', n_saved=1, create_dir=True, score_function=score_function, score_name='val_loss')\n",
    "\n",
    "# evaluator.add_event_handler(Events.COMPLETED, checkpoint_handler, {'model': model})\n",
    "evaluator.add_event_handler(Events.COMPLETED, checkpoint_handler, {'model': model})\n",
    "\n",
    "# Setup early stopping\n",
    "early_stopper = EarlyStopping(patience=10, score_function=score_function, trainer=trainer)\n",
    "evaluator.add_event_handler(Events.COMPLETED, early_stopper)\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def run_validation(engine):\n",
    "    evaluator.run(val_loader)\n",
    "\n",
    "trainer.run(train_loader, max_epochs=num_epochs)\n",
    "\n",
    "# The best model is saved with the prefix 'checkpoint' in the directory './models'\n",
    "# You can rename it here if you like\n",
    "best_model_path = os.path.join(model_dir, 'best_model.pth')\n",
    "os.rename(checkpoint_handler.last_checkpoint, best_model_path)\n",
    "print(f\"The best model has been saved as {best_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CheckpointSaver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Initialize early stopping\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, score_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m-\u001b[39mx, saver\u001b[38;5;241m=\u001b[39m\u001b[43mCheckpointSaver\u001b[49m(save_dir\u001b[38;5;241m=\u001b[39mmodel_dir, save_dict\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: model}, save_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Initialize best validation loss for comparison\u001b[39;00m\n\u001b[0;32m     24\u001b[0m best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CheckpointSaver' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.handlers import EarlyStopping, ModelCheckpoint\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, ScaleIntensityd, ToTensord\n",
    ")\n",
    "from monai.data import CacheDataset, DataLoader\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "\n",
    "num_epochs = 5\n",
    "model_dir = './models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "model_path = os.path.join(model_dir, 'best_model.pth')\n",
    "\n",
    "# Initialize early stopping\n",
    "early_stopping = EarlyStopping(patience=10, score_function=lambda x: -x, saver=CheckpointSaver(save_dir=model_dir, save_dict={'model': model}, save_key='val_loss'))\n",
    "\n",
    "# Initialize best validation loss for comparison\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch_data in train_loader:\n",
    "        inputs, labels = batch_data['image'], batch_data['label']\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_data in val_loader:\n",
    "            inputs, labels = batch_data['image'], batch_data['label']\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    # Calculate average losses\n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss /= len(val_loader)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "    # Check if this is the best model (based on validation loss)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), model_path)  # Save the best model\n",
    "        \n",
    "    # Early stopping check\n",
    "    early_stopping(epoch, val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "# After training, you might want to rename the best model\n",
    "final_model_path = os.path.join(model_dir, 'final_best_model.pth')\n",
    "os.rename(model_path, final_model_path)\n",
    "print(f\"The best model has been saved as {final_model_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the training step\n",
    "def train_step(engine, batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    inputs, labels = batch['image'], batch['label']\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_function(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "trainer = Engine(train_step)\n",
    "\n",
    "# Define the validation step\n",
    "def validation_step(engine, batch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs, labels = batch['image'], batch['label']\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "    return loss.item()\n",
    "\n",
    "evaluator = Engine(validation_step)\n",
    "\n",
    "# Define the score function for early stopping\n",
    "def score_function(engine):\n",
    "    return -engine.state.metrics['average_loss']\n",
    "\n",
    "# Attach the validation metric (loss) to the evaluator\n",
    "from ignite.metrics import RunningAverage\n",
    "RunningAverage(output_transform=lambda x: x).attach(evaluator, 'average_loss')\n",
    "\n",
    "# Setup model checkpoint to save the best model based on validation loss\n",
    "checkpoint_handler = ModelCheckpoint(model_dir, 'checkpoint', n_saved=1, create_dir=True, score_function=score_function, score_name='val_loss', global_step_transform=global_step_from_engine(trainer))\n",
    "evaluator.add_event_handler(Events.COMPLETED, checkpoint_handler, {'model': model})\n",
    "\n",
    "# Setup early stopping\n",
    "early_stopper = EarlyStopping(patience=10, score_function=score_function, trainer=trainer)\n",
    "evaluator.add_event_handler(Events.COMPLETED, early_stopper)\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def run_validation(engine):\n",
    "    evaluator.run(val_loader)\n",
    "\n",
    "trainer.run(train_loader, max_epochs=num_epochs)\n",
    "\n",
    "# The best model is saved with the prefix 'checkpoint' in the directory './models'\n",
    "# You can rename it here if you like\n",
    "best_model_path = os.path.join(model_dir, 'best_model.pth')\n",
    "os.rename(checkpoint_handler.last_checkpoint, best_model_path)\n",
    "print(f\"The best model has been saved as {best_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.handlers import EarlyStopping\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, ScaleIntensityd, ToTensord\n",
    ")\n",
    "from monai.data import CacheDataset, DataLoader\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "\n",
    "\n",
    "# Training step function\n",
    "def train_step(engine, batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    inputs, labels = batch['image'], batch['label']\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_function(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# Validation step function\n",
    "def validation_step(engine, batch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs, labels = batch['image'], batch['label']\n",
    "        outputs = model(inputs)\n",
    "        return outputs, labels\n",
    "\n",
    "# Score function for early stopping\n",
    "def score_function(engine):\n",
    "    val_loss = engine.state.metrics['average_loss']\n",
    "    return -val_loss\n",
    "\n",
    "trainer = Engine(train_step)\n",
    "evaluator = Engine(validation_step)\n",
    "\n",
    "# Attach metrics to the evaluator\n",
    "val_metrics = {\n",
    "    'average_loss': Loss(loss_function),\n",
    "    'dice_metric': DiceMetric(include_background=True, reduction=\"mean\")\n",
    "}\n",
    "for name, metric in val_metrics.items():\n",
    "    metric.attach(evaluator, name)\n",
    "\n",
    "# EarlyStopping handler to stop training after no improvement\n",
    "handler = EarlyStopping(patience=10, score_function=score_function, trainer=trainer)\n",
    "evaluator.add_event_handler(Events.COMPLETED, handler)\n",
    "\n",
    "# Function to run the evaluator on the validation dataset\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def run_validation(engine):\n",
    "    evaluator.run(val_loader)\n",
    "\n",
    "# Function to save the model after each epoch\n",
    "best_val_loss = float('inf')\n",
    "model_dir = './models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def save_best_model(engine):\n",
    "    global best_val_loss\n",
    "    current_val_loss = evaluator.state.metrics['average_loss']\n",
    "    if current_val_loss < best_val_loss:\n",
    "        best_val_loss = current_val_loss\n",
    "        torch.save(model.state_dict(), os.path.join(model_dir, 'best_model.pth'))\n",
    "\n",
    "# Running the training process\n",
    "trainer.run(train_loader, max_epochs=100)\n",
    "\n",
    "# Optional: Rename the best model at the end\n",
    "final_model_path = os.path.join(model_dir, 'final_best_model.pth')\n",
    "os.rename(os.path.join(model_dir, 'best_model.pth'), final_model_path)\n",
    "print(f\"The best model has been saved as {final_model_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
